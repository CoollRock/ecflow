%include <head.h>

#===============================================================
# defines variable WK 
#===============================================================
%include <export_WK.h>
cd $WK

#===============================================================
# run the regression tests: Don't re-run test if already passed
# If test exe is rebuilt, then re-run the test
#===============================================================

# the variable COMPILER_TEST_PATH will embed $mode, mode can be one of [ debug | release | profile ]
mode=%MODE%

echo "*****************************************"
echo "Testing: variant=$mode compiler=%TOOLSET%"
echo "*****************************************"

ecflow_client --label=progress core/nodeattr/nodeAParser   --host=%ECF_NODE% --port=%ECF_PORT%  

# ================================================================================
# Test built with Boost build
# ================================================================================
run_test_boost()
{
   # Run the test, if the test passes don't rerun again
   # This is done by touching a file named after the test and mode(debug or release)
   # This makes the test pass file unique.
   # if test executable is newer then the test pass file then rerun test
   #
   # $1 = Project directory
   # $2 = test name executable

# The following lines are required for aborting a test, function ERROR must be defined
trap '{ echo "Error in function"; ERROR; }' 0 1 2 3 4 5 6 7 8 10 12 13 15
set -e # stop shell, on error
set -x # echo script lines as they are executed

%ecfmicro ^

   #
   # we use TOOLSET since its possible to get different compilers on the same platform
   # If ever use different versions of the same compiler may need COMPILER_VERSION
   #
   exe_time=`date +%s -r $1/bin/^COMPILER_TEST_PATH^/$2`
   passed_file_time=0
   if test -r $1/bin/$2_^TOOLSET^_^MODE^_passed
   then
      passed_file_time=`date +%s -r $1/bin/$2_^TOOLSET^_^MODE^_passed`
   fi

^ecfmicro %


   if test $exe_time -gt $passed_file_time
   then
      $1/bin/%COMPILER_TEST_PATH%/$2 --log_level=message
      if [ "$?" -eq 0 ] ; then
         touch $1/bin/$2_%TOOLSET%_%MODE%_passed
      fi
   fi
   
   # required for aborting form errors
   set -e; trap 0; return 0 ##### reset trap
}

# ================================================================================
# Test built with CMAKE
# ================================================================================
run_test_cmake()
{
   # Run cmake test, if the test passes don't rerun again
   # This is done by touching a file named after the test and mode(debug or release)
   # This makes the test pass file unique.
   # if test executable is newer then the test pass file then rerun test
   #
   # $1 = Project directory
   # $2 = test name executable

# The following lines are required for aborting a test, function ERROR must be defined
trap '{ echo "Error in function"; ERROR; }' 0 1 2 3 4 5 6 7 8 10 12 13 15
set -e # stop shell, on error
set -x # echo script lines as they are executed

%ecfmicro ^

   #
   # we use TOOLSET since its possible to get different compilers on the same platform
   # If ever use different versions of the same compiler may need COMPILER_VERSION
   #
   exe_time=`date +%s -r ecbuild/^MODE^/$1/$2`
   passed_file_time=0
   if test -r ecbuild/^MODE^/$1/$2_^TOOLSET^_^MODE^_passed
   then
      passed_file_time=`date +%s -r ecbuild/^MODE^/$1/$2_^TOOLSET^_^MODE^_passed`
   fi

^ecfmicro %


   if test $exe_time -gt $passed_file_time
   then
      ecbuild/%MODE%/$1/$2 --log_level=message
      if [ "$?" -eq 0 ] ; then
         touch ecbuild/%MODE%/$1/$2_%TOOLSET%_%MODE%_passed
      fi
   fi
   
   # required for aborting form errors
   set -e; trap 0; return 0 ##### reset trap
}


# ================================================================================
# run_test  decide between boost and cmake tests
# ================================================================================
run_test()
{
   # Run the test, if the test passes don't rerun again
   # This is done by touching a file named after the test and mode(debug or release)
   # This makes the test pass file unique.
   # if test executable is newer then the test pass file then rerun test
   #
   # $1 = Project directory
   # $2 = test name executable

# The following lines are required for aborting a test, function ERROR must be defined
trap '{ echo "Error in function"; ERROR; }' 0 1 2 3 4 5 6 7 8 10 12 13 15
set -e # stop shell, on error
set -x # echo script lines as they are executed

   # This was enable because this allowed us to only run the failed tests
   #if [[ %BUILD_TYPE:boost% = cmake ]] ; then
   #   run_test_cmake $1 $2
   #else
      run_test_boost $1 $2
   #fi

   # required for aborting form errors
   set -e; trap 0; return 0 ##### reset trap
}

# ============================================================================

if [[ %ARCH% = linux64intel  ]] ; then
   #
   # NOTE: /usr/local/apps/python/2.7.2-01/bin/ provides path to PYTHON interpreter
   #       This is what 'using python' will pick up and add to the include path
   #
   export PATH=/usr/local/apps/intel/composer_xe_2013.3.163/bin:$PATH
   
   # ensure any variable exported will form part of this script.
   # Ignore errors in the script, re-enable afterwards.
   # If all else fails we only need LD_LIBRARY_PATH
   #   export LD_LIBRARY_PATH=/gpfs/usr/local/apps/intel/composer_xe_2013.3.163/composer_xe_2013.3.163/ipp/../compiler/lib/intel64:/gpfs/usr/local/apps/intel/composer_xe_2013.3.163/composer_xe_2013.3.163/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/gpfs/usr/local/apps/intel/composer_xe_2013.3.163/composer_xe_2013.3.163/compiler/lib/intel64:/gpfs/usr/local/apps/intel/composer_xe_2013.3.163/composer_xe_2013.3.163/mkl/lib/intel64:/gpfs/usr/local/apps/intel/composer_xe_2013.3.163/composer_xe_2013.3.163/tbb/lib/intel64/gcc4.1
   #
   # Needed so that we can find (intel)libimf.so, which is loaded when call ecflow python extension
   set +eux
   . iccvars.sh intel64
   set -eux
fi
      
# =================================================================================

if [[ %SET_TO_TEST_SCRIPT% = true ]] ; then
   echo "Test only"
else
   if [[ %BUILD_TYPE:boost% = cmake ]] ; then
      ############################################################################
      # ctest
      ############################################################################
      ecflow_client --label=progress ctest   --host=%ECF_NODE% --port=%ECF_PORT% 
   
      # The following lines are required for aborting a test, function ERROR must be defined
      trap '{ echo "Error in function"; ERROR; }' 0 1 2 3 4 5 6 7 8 10 12 13 15
      set -e # stop shell, on error
      set -x # echo script lines as they are executed
   
      # now run the ctest, which will also run python tests.
      cd $WK
      cd ecbuild/%MODE%
        
      #  Uset ECF variables that could be used in ecf tests
      unset ECF_HOME
      unset ECF_PORT
      unset ECF_NODE
      unset ECF_RID
      
      # Use the ctest in /usr/local/apps/cmake/current/bin
      export PATH=/usr/local/apps/cmake/current/bin:$PATH
            
      # -V verbose, show test output
      # -VV extra verbose 
      # --output-on-failure only show output on failure
      #
      if [[ %ECF_TRYNO% -eq 1 ]] ; then
         ctest -R u_ -V
         ctest -R py_u -V
         ctest -R py_s -V
         ctest -R c_ -V
         ctest -R s_ -V
         ctest -R perf_ -V
      else
         # this does not work
         # ctest --rerun-failed --output-on-failure
         #
         # Create a file('FailedTests.log') with all the failed tests
         cmake -P $WK/CMAKE_failed_tests.txt
         sleep 4
         
         # Only run the failed test. Note: if FailedTests.log is empty then all tests are run
         # -VV extra verbose
         ctest -I FailedTests.log -VV
      fi
      
   else
      ############################################################################
      # Boost unit,integration,regression tests
      ############################################################################

      run_test ACore   u_acore
      run_test ANattr  u_anattr
      run_test ANode   u_anode
      run_test AParser u_aparser
      
      ecflow_client --meter=progress 20             --host=%ECF_NODE% --port=%ECF_PORT%  
      ecflow_client --label=progress Base           --host=%ECF_NODE% --port=%ECF_PORT%
      
      run_test Base u_base
      
      #============================ simulator  ========================================
      ecflow_client --meter=progress 25             --host=%ECF_NODE% --port=%ECF_PORT%  
      ecflow_client --label=progress Simulator      --host=%ECF_NODE% --port=%ECF_PORT%  
      
      run_test CSim c_csim
      
      #============================ Parser a big file  ========================================
      ecflow_client --meter=progress 35             --host=%ECF_NODE% --port=%ECF_PORT%  
      ecflow_client --label=progress ParseMega      --host=%ECF_NODE% --port=%ECF_PORT%  
      
      run_test AParser perf_aparser
   
      #============================ Server  ========================================
      ecflow_client --meter=progress 45             --host=%ECF_NODE% --port=%ECF_PORT%  
      ecflow_client --label=progress Server         --host=%ECF_NODE% --port=%ECF_PORT%
      
      # ECF_RID can be set for Cray, this can mess up python tests, hence unset
      if [[ %ARCH% = cray ]] ; then
         unset ECF_HOME
         unset ECF_PORT
         unset ECF_NODE
         unset ECF_RID
      fi
      run_test Server u_server
      
      
      #============================ Client ========================================
      ecflow_client --meter=progress 45             --host=%ECF_NODE% --port=%ECF_PORT%  
      ecflow_client --label=progress Client         --host=%ECF_NODE% --port=%ECF_PORT% 
      
      run_test Client s_client
      
      
      #============================ Test ========================================
      ecflow_client --meter=progress 60     --host=%ECF_NODE% --port=%ECF_PORT%  
      ecflow_client --label=progress Test   --host=%ECF_NODE% --port=%ECF_PORT%  
      
      if [[ %ARCH% = opensuse113 || %ARCH% = opensuse103 || %ARCH% = redhat ]] ; then
         # On ECGATE/opensuse113 port 3141 is already used ???
         # linux64 and linux64intel, run at the same time, hence use ECF_PORT=3142 for linux64intel
         export ECF_PORT=3142
      fi
      
      run_test Test s_test
      
      
      #============================ Test zombies ========================================
      ecflow_client --meter=progress 80        --host=%ECF_NODE% --port=%ECF_PORT%  
      ecflow_client --label=progress Zombies   --host=%ECF_NODE% --port=%ECF_PORT% 
      
      if [ %ECF_TRYNO% -gt 1 ] ; then
         export ECF_DEBUG_ZOMBIES=1
      fi
      run_test Test s_test_zombies
      
      
      #============================ Python ========================================
      # placed last since bjam invocation appears to hang occasionally on HPUX
      
      ecflow_client --meter=progress 90       --host=%ECF_NODE% --port=%ECF_PORT%  
      ecflow_client --label=progress Python   --host=%ECF_NODE% --port=%ECF_PORT%  
      
      cd Pyext
      
      # make sure path to the interpreter is accessible.
      echo $PATH
      
      #rm -rf bin/*.test   
      
      # On cray we need CUSTOM_BJAM_ARGS i.e for toolset=intel cxxflags=-fPIC otherwise, 
      # it will rebuild Pyext directory with default compiler
      # hence thses flags need to be same used in build.ecf
      %BOOST_DIR%/%BOOST_VERSION%/bjam %CUSTOM_BJAM_ARGS:% variant=$mode test-all
   fi
fi

# ========================= all test complete ==========================================
ecflow_client --meter=progress 100 --host=%ECF_NODE% --port=%ECF_PORT% 

%include <tail.h>
